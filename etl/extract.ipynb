{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from .txt files using an LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install required libraries\n",
    "\n",
    "Load the required libraries and set up the environment.\n",
    "#!pip install -r requirements.txt\n",
    "!source ../.env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS_ACCESS_KEY_ID: AKIAVQQPQBS2UDIGWL54\n",
      "AWS_SECRET_ACCESS_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "AWS_ACCESS_KEY_ID = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "AWS_SECRET_ACCESS_KEY = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "print(f\"AWS_ACCESS_KEY_ID: {AWS_ACCESS_KEY_ID}\")\n",
    "print(f\"AWS_SECRET_ACCESS_KEY: {AWS_SECRET_ACCESS_KEY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_MODELS = {\n",
    "    \"aws-titan\": {\n",
    "        \"g1-lite\": \"amazon.titan-text-lite-v1\",\n",
    "        \"text-premier\": \"amazon.titan-text-premier-v1\",\n",
    "    },\n",
    "    \"aws-nova\": {\n",
    "        \"micro\": \"amazon.nova-micro-v1:0\",\n",
    "        \"lite\": \"amazon.nova-lite-v1:0\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(\n",
    "    retries={\n",
    "        \"max_attempts\": 8,\n",
    "    }\n",
    ")\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "\n",
    "def llm_aws_titan_inference(\n",
    "    prompt: str, model_name: str = \"amazon.titan-text-premier-v1:0\"\n",
    "):\n",
    "    \"\"\"Call the Bedrock runtime API to get the response from the model\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the model\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the env vars are missing\n",
    "\n",
    "    Returns:\n",
    "        json_response (dict): The response from the model\n",
    "    \"\"\"\n",
    "    if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:\n",
    "        raise ValueError(\n",
    "            \"Missing env variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY\"\n",
    "        )\n",
    "\n",
    "    kwargs = {\n",
    "        \"modelId\": model_name,\n",
    "        \"contentType\": \"application/json\",\n",
    "        \"accept\": \"*/*\",\n",
    "        \"body\": json.dumps({\"inputText\": prompt}),\n",
    "    }\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(**kwargs)\n",
    "    json_response: dict = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    return json_response\n",
    "\n",
    "\n",
    "def llm_aws_nova_inference(\n",
    "    prompt: str, model_name: str = AVAILABLE_MODELS[\"aws-nova\"][\"micro\"]\n",
    "):\n",
    "    \"\"\"Call the Bedrock runtime API to get the response from the model\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the model\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the env vars are missing\n",
    "\n",
    "    Returns:\n",
    "        json_response (dict): The response from the model\n",
    "    \"\"\"\n",
    "    if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:\n",
    "        raise ValueError(\n",
    "            \"Missing env variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY\"\n",
    "        )\n",
    "\n",
    "    kwargs = {\n",
    "        \"modelId\": model_name,\n",
    "        \"contentType\": \"application/json\",\n",
    "        \"accept\": \"application/json\",\n",
    "        \"body\": json.dumps(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\"text\": prompt}],\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(**kwargs)\n",
    "    json_response: dict = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'message': {'content': [{'text': '2 + 2 equals 4. This is a basic arithmetic operation in mathematics, where you add the values together. If you have any more questions or need further assistance, feel free to ask!'}], 'role': 'assistant'}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 7, 'outputTokens': 41, 'totalTokens': 48, 'cacheReadInputTokenCount': 0, 'cacheWriteInputTokenCount': 0}}\n"
     ]
    }
   ],
   "source": [
    "x = llm_aws_nova_inference(\"What is 2+2?\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputTextTokenCount': 1, 'results': [{'tokenCount': 81, 'outputText': 'Hello! How may I assist you today? I am here to provide information, answer questions, and help you with any tasks you may have. Whether you need information on a specific topic, want to know about a particular subject, or need assistance with a task, I am here to help. Feel free to ask me anything, and I will do my best to provide you with accurate and relevant information.', 'completionReason': 'FINISH'}]}\n"
     ]
    }
   ],
   "source": [
    "x = llm_aws_titan_inference(\"Hello\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    open(\"prompts/file_extract.txt\") as file_extract_prompt,\n",
    "    open(\"extracts/extracto_202503_tarjeta_visa_5216.txt\") as bank_extract_txt,\n",
    "):\n",
    "    file_extract_prompt_text = file_extract_prompt.read()\n",
    "    bank_extract = bank_extract_txt.read()\n",
    "\n",
    "    file_extract_prompt_text = file_extract_prompt_text.format(\n",
    "        bank_extract=bank_extract,\n",
    "    )\n",
    "    response = llm_aws_nova_inference(file_extract_prompt_text)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "# Fix the JSON string to be valid\n",
    "\n",
    "\n",
    "with open(\"extracts/extracto_202503_tarjeta_visa_5216.json\", \"w\") as json_file:\n",
    "    json_file.write(json_string)\n",
    "\n",
    "\n",
    "# loaded_json = json.loads(response[\"results\"][0][\"outputText\"], strict=False)\n",
    "# print(loaded_json)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
